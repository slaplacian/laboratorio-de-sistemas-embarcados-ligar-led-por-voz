# Treinamento de Modelo de Reconhecimento de Voz

Este diret√≥rio cont√©m os scripts e recursos utilizados para treinar um modelo de reconhecimento de voz capaz de identificar os comandos "on" e "off". O objetivo √© gerar um modelo que possa ser integrado ao sistema embarcado para controlar um LED via comandos de voz.

## Dataset Utilizado

O modelo √© treinado utilizando o [Google Speech Commands Dataset v0.02](https://www.kaggle.com/datasets/yashdogra/speech-commands/code), que cont√©m milhares de grava√ß√µes de palavras faladas por diferentes pessoas.

## Como Baixar o Dataset do Kaggle

1. **Crie uma conta no Kaggle**: Acesse [https://www.kaggle.com](https://www.kaggle.com) e registre-se.

2. **Obtenha seu token de API**:
   - V√° para [https://www.kaggle.com/account](https://www.kaggle.com/account).
   - Role at√© a se√ß√£o "API" e clique em **"Create New API Token"**.
   - Um arquivo chamado `kaggle.json` ser√° baixado. Guarde-o em um local seguro.

3. **Configure o ambiente local**:
   - Instale a biblioteca do Kaggle:
     ```bash
     pip install kaggle
     ```
   - Mova o arquivo `kaggle.json` para o diret√≥rio apropriado:
     - **Linux/Mac**:
       ```bash
       mkdir -p ~/.kaggle
       mv /caminho/para/kaggle.json ~/.kaggle/
       chmod 600 ~/.kaggle/kaggle.json
       ```
     - **Windows**:
       - Crie a pasta `C:\Users\<SeuUsu√°rio>\.kaggle\` e mova o `kaggle.json` para l√°.

4. **Baixe o dataset**:
   - Execute o seguinte comando:
     ```bash
     kaggle datasets download -d yashdogra/speech-commands
     ```
   - Extraia o conte√∫do:
     ```bash
     unzip speech-commands.zip -d speech_commands
     ```

## Prepara√ß√£o dos Dados

1. **Sele√ß√£o de Palavras**:
   - O foco √© nas palavras **"on"** e **"off"**.
   - Cada uma possui aproximadamente 2.300 grava√ß√µes.

2. **Adi√ß√£o de Ru√≠do de Fundo**:
   - Para melhorar a robustez do modelo, √© recomend√°vel incluir amostras de ru√≠do de fundo.
   - O dataset cont√©m uma pasta `_background_noise_` com arquivos de ru√≠do que podem ser utilizados para essa finalidade.

## Treinamento do Modelo

1. **Pr√©-processamento**:
   - Os arquivos de √°udio s√£o convertidos em representa√ß√µes de espectrograma ou MFCC (Mel-Frequency Cepstral Coefficients) para serem utilizados como entrada do modelo.

2. **Arquitetura do Modelo**:
   - Utiliza-se uma rede neural simples com camadas densas e/ou convolucionais.
   - A sa√≠da √© uma camada softmax com tr√™s classes: "on", "off" e "background".

3. **Treinamento**:
   - O treinamento √© realizado utilizando o TensorFlow ou outra biblioteca de aprendizado de m√°quina.
   - Ap√≥s o treinamento, o modelo √© convertido para um formato compat√≠vel com o sistema embarcado, como o TensorFlow Lite.

## üìÅ Estrutura dos Arquivos

- `main.py`: Script principal para treinamento do modelo.
- `conversor.py`: Script para converter o modelo treinado para TensorFlow Lite (`.tflite`).
- `runtime.py`: Script para executar e testar localmente a infer√™ncia com o modelo `.tflite`.
